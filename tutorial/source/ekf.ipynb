{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalman Filter\n",
    "\n",
    "Kalman filters are linear models for state estimation of dynamic systems [1].  They have been the <i>de facto</i> standard in many robotics and tracking/prediction applications because they are well suited for systems with uncertainty about an observable dynamic process.  They use a \"observe, predict, correct\" paradigm to extract information from an otherwise noisy signal. In Pyro, we can build differentiable Kalman filters using the [`pyro.contrib.tracking` library](http://docs.pyro.ai/en/dev/contrib.tracking.html#module-pyro.contrib.tracking.extended_kalman_filter)\n",
    "\n",
    "## Dynamic process\n",
    "\n",
    "To start, consider this simple motion model:\n",
    "\n",
    "$$ X_{k+1} = FX_k + \\mathbf{W}_k $$\n",
    "$$ \\mathbf{Z}_k = HX_k + \\mathbf{V}_k $$\n",
    "\n",
    "where $k$ is the state, $X$ is the signal estimate, $Z_k$ is the observed value at timestep $k$, $\\mathbf{W}_k$ and  $\\mathbf{V}_k$ are independent noise processes (ie $\\mathbb{E}[w_k v_j^T] = 0$ for all $j, k$) which we'll approximate as Gaussians. Note that the state transitions are linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kalman Update\n",
    "At each time step, we perform a prediction for the mean and covariance:\n",
    "$$ \\hat{X}_k = F\\hat{X}_{k-1}$$\n",
    "$$\\hat{P}_k = FP_{k-1}F^T + Q$$\n",
    "and a correction for the measurement:\n",
    "$$ K_k = \\hat{P}_k H^T(H\\hat{P}_k H^T + R)^{-1}$$\n",
    "$$ X_k = \\hat{X}_k + K_k(z_k - H\\hat{X}_k)$$\n",
    "$$ P_k = (I-K_k H)\\hat{P}_k$$\n",
    "\n",
    "where $X$ is the position estimate, $P$ is the covariance matrix, $K$ is the Kalman Gain, and $Q$ and $R$ are covariance matrices.\n",
    "\n",
    "For an in-depth derivation, see \\[1\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinear Estimation: Extended Kalman Filter\n",
    "\n",
    "What if our system is non-linear, eg in GPS navigation?  Consider this non-linear system:\n",
    "\n",
    "$$ X_{k+1} = \\mathbf{f}(X_k) + \\mathbf{W}_k $$\n",
    "$$ \\mathbf{Z}_k = \\mathbf{h}(X_k) + \\mathbf{V}_k $$\n",
    "\n",
    "Notice that $\\mathbf{f}$ and $\\mathbf{h}$ are now (smooth) non-linear functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Extended Kalman Filter (EKF) attacks this problem by using a local linearization of the Kalman filter via a [Taylors Series expansion](https://en.wikipedia.org/wiki/Taylor_series).\n",
    "\n",
    "$$ f(X_k, k) \\approx f(x_k^R, k) + \\mathbf{H}_k(X_k - x_k^R) + \\cdots$$\n",
    "\n",
    "where $\\mathbf{H}_k$ is the Jacobian matrix at time $k$, $x_k^R$ is the previous optimal estimate, and we ignore the higher order terms.  At each time step, we compute a Jacobian conditioned the previous predictions (this computation is handled for us under the hood), and use the result to perform a prediction and update.\n",
    "\n",
    "Omitting the derivations, the modification to the above predictions are now:\n",
    "$$ \\hat{X}_k \\approx \\mathbf{f}(X_{k-1}^R)$$\n",
    "$$ \\hat{P}_k = \\mathbf{H}_\\mathbf{f}(X_{k-1})P_{k-1}\\mathbf{H}_\\mathbf{f}^T(X_{k-1}) + Q$$\n",
    "and the updates are now:\n",
    "$$ X_k \\approx \\hat{X}_k + K_k\\big(z_k - \\mathbf{h}(\\hat{X}_k)\\big)$$\n",
    "$$ K_k = \\hat{P}_k \\mathbf{H}_\\mathbf{h}(\\hat{X}_k) \\Big(\\mathbf{H}_\\mathbf{h}(\\hat{X}_k)\\hat{P}_k \\mathbf{H}_\\mathbf{h}(\\hat{X}_k) + R_k\\Big)^{-1} $$\n",
    "$$ P_k = \\big(I - K_k \\mathbf{H}_\\mathbf{h}(\\hat{X}_k)\\big)\\hat{P}_K$$\n",
    "\n",
    "In Pyro, all we need to do is create an `EKFState` object and use its `predict` and `update` methods. Pyro will do exact inference to compute the innovations and we will use SVI to learn a MAP estimate of the position and measurement covariances.\n",
    "\n",
    "As an example, let's look at an object moving at near-constant velocity in 2-D in a discrete time space over 100 time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import pyro\n",
    "from pyro.distributions import HalfCauchy, MultivariateNormal\n",
    "from pyro.contrib.autoguide import AutoDelta\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, Trace_ELBO, config_enumerate\n",
    "from pyro.contrib.tracking.extended_kalman_filter import EKFState\n",
    "from pyro.contrib.tracking.distributions import EKFDistribution\n",
    "from pyro.contrib.tracking.dynamic_models import NcvContinuous\n",
    "from pyro.contrib.tracking.measurements import PositionMeasurement\n",
    "\n",
    "smoke_test = ('CI' in os.environ)\n",
    "pyro.enable_validation(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discrete time\n",
    "dt = 1 / 100\n",
    "num_frames = 10\n",
    "dim = 4\n",
    "\n",
    "# Continuous model\n",
    "ncv = NcvContinuous(dimension=dim, sa2=2.0)\n",
    "\n",
    "# Truth trajectory\n",
    "xs_truth = torch.zeros(num_frames, dim)\n",
    "# initial direction\n",
    "theta0_truth = 0.0\n",
    "# initial state\n",
    "xs_truth[0, :] = torch.tensor([0.0, 0.0,  math.cos(theta0_truth), math.sin(theta0_truth)])\n",
    "for frame_num in range(1, num_frames):\n",
    "    # sample independent process noise\n",
    "    dx = pyro.sample('process_noise_{}'.format(frame_num), ncv.process_noise_dist(dt))\n",
    "    xs_truth[frame_num, :] = ncv(xs_truth[frame_num-1, :], dt=dt) + dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measurements\n",
    "measurements = []\n",
    "mean = torch.zeros(2)\n",
    "# no correlations\n",
    "cov = 1e-5 * torch.eye(2)\n",
    "# sample independent measurement noise\n",
    "dzs = pyro.sample('dzs', MultivariateNormal(mean, cov).expand((num_frames,)))\n",
    "# compute measurement means\n",
    "zs = xs_truth[:, :2] + dzs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data):\n",
    "    # TODO replace this with HalfNormal\n",
    "    R = pyro.sample('R', dist.HalfCauchy(2e-6)) * torch.eye(4)\n",
    "    Q = pyro.sample('Q', dist.HalfCauchy(1e-6)) * torch.eye(2)\n",
    "    # observe the measurements\n",
    "    pyro.sample('track_{}'.format(i), EKFDistribution(xs_truth[0], R, ncv,\n",
    "                                                      Q, time_steps=num_frames),\n",
    "                obs=data)\n",
    "    \n",
    "guide = AutoDelta(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  -10.265189170837402\n",
      "loss:  -10.808286666870117\n",
      "loss:  -11.267187118530273\n",
      "loss:  -11.635580062866211\n",
      "loss:  -11.912515640258789\n",
      "loss:  -12.10242748260498\n",
      "loss:  -12.216792106628418\n",
      "loss:  -12.274310111999512\n",
      "loss:  -12.297000885009766\n",
      "loss:  -12.303607940673828\n",
      "loss:  -12.305276870727539\n",
      "loss:  -12.306243896484375\n",
      "loss:  -12.307249069213867\n",
      "loss:  -12.308155059814453\n",
      "loss:  -12.308900833129883\n",
      "loss:  -12.30950927734375\n",
      "loss:  -12.310028076171875\n",
      "loss:  -12.310478210449219\n",
      "loss:  -12.310866355895996\n",
      "loss:  -12.311205863952637\n"
     ]
    }
   ],
   "source": [
    "optim = pyro.optim.Adam({'lr': 2e-2})\n",
    "svi = SVI(model, guide, optim, loss=Trace_ELBO())\n",
    "\n",
    "pyro.set_rng_seed(0)\n",
    "pyro.clear_param_store()\n",
    "\n",
    "for i in range(100 if not smoke_test else 2):\n",
    "    loss = svi.step(zs)\n",
    "    if not i % 10:\n",
    "        print('loss: ', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto_R tensor(6.0387e-06, grad_fn=<AddBackward>)\n",
      "auto_Q tensor(1.9711e-07, grad_fn=<AddBackward>)\n"
     ]
    }
   ],
   "source": [
    "for i in pyro.get_param_store().get_all_param_names():\n",
    "    print(i, pyro.param(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "R = guide()['R'] * torch.eye(4)\n",
    "Q = guide()['Q'] * torch.eye(2)\n",
    "ekf_dist = EKFDistribution(xs_truth[0], R, ncv, Q, time_steps=num_frames)\n",
    "states= ekf_dist.get_states(zs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 0.0],\n",
       " [0.010107642970979214, -6.847964868939016e-06],\n",
       " [0.020236091688275337, -0.0001418385945726186],\n",
       " [0.03030969947576523, -0.0001620639959583059],\n",
       " [0.04040909931063652, -9.933050023391843e-06],\n",
       " [0.05033167451620102, 0.00024324559490196407],\n",
       " [0.06021888926625252, 0.0006623838562518358],\n",
       " [0.0702277421951294, 0.0010909209959208965],\n",
       " [0.08015932142734528, 0.0015986886573955417],\n",
       " [0.0900019183754921, 0.0019451151601970196]]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TRUTH\n",
    "[x[:2] for x in xs_truth.numpy().tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.0047094551846385, 0.003680370980873704],\n",
       " [0.009187041781842709, 0.0009707469143904746],\n",
       " [0.018267622217535973, -0.003966068848967552],\n",
       " [0.026824595406651497, 0.003120339708402753],\n",
       " [0.039249252527952194, -0.0023127663880586624],\n",
       " [0.05123267322778702, -0.00259613711386919],\n",
       " [0.06542954593896866, -0.009974617511034012],\n",
       " [0.07483357191085815, -0.0030986773781478405],\n",
       " [0.07863657176494598, 0.0004923918750137091],\n",
       " [0.0964636355638504, -0.0014208999928086996]]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# MEASUREMENT MEANS\n",
    "zs.numpy().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.004560594912618399, 0.00356403854675591],\n",
       " [0.009187281131744385, 0.0009707475546747446],\n",
       " [0.018267542123794556, -0.003966068848967552],\n",
       " [0.026824623346328735, 0.00312033761292696],\n",
       " [0.0392492450773716, -0.0023127617314457893],\n",
       " [0.05123267322778702, -0.0025961389765143394],\n",
       " [0.06542954593896866, -0.009974615648388863],\n",
       " [0.07483357191085815, -0.003098679706454277],\n",
       " [0.07863657176494598, 0.000492393970489502],\n",
       " [0.0964636355638504, -0.0014208992943167686]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STATE MEANS\n",
    "[s.mean[:2].detach().numpy().tolist() for s in states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[3.5885700526705477e-06, 0.0], [0.0, 3.5885700526705477e-06]],\n",
       " [[3.877793915307848e-06, 0.0], [0.0, 3.877793915307848e-06]],\n",
       " [[3.8778030102548655e-06, 0.0], [0.0, 3.8778030102548655e-06]],\n",
       " [[3.877803919749567e-06, 0.0], [0.0, 3.877803919749567e-06]],\n",
       " [[3.877803919749567e-06, 0.0], [0.0, 3.877803919749567e-06]],\n",
       " [[3.877803919749567e-06, 0.0], [0.0, 3.877803919749567e-06]],\n",
       " [[3.877803919749567e-06, 0.0], [0.0, 3.877803919749567e-06]],\n",
       " [[3.877803919749567e-06, 0.0], [0.0, 3.877803919749567e-06]],\n",
       " [[3.877803919749567e-06, 0.0], [0.0, 3.877803919749567e-06]],\n",
       " [[3.877803919749567e-06, 0.0], [0.0, 3.877803919749567e-06]]]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STATE COV\n",
    "[s.cov[:2, :2].detach().numpy().tolist() for s in states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[9.999999747378752e-06, 0.0], [0.0, 9.999999747378752e-06]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov.numpy().tolist()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/html"
   },
   "source": [
    "<center><figure>\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td> \n",
    "                <img src=\"_static/img/ekf_track.png\" style=\"width: 450px;\">\n",
    "            </td>\n",
    "        </tr>\n",
    "    </table> <center>\n",
    "    <figcaption> \n",
    "        <font size=\"+1\"><b>Figure 1:</b>True track and EKF prediction with error. </font> \n",
    "    </figcaption> </center>\n",
    "</figure></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
