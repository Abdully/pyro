{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kalman Filter\n",
    "\n",
    "Kalman filters are linear models for state estimation of dynamic systems [1].  They have been the <i>de facto</i> standard in many robotics and tracking/prediction applications because they are well suited for systems with uncertainty about an observable dynamic process.  They use a \"observe, predict, correct\" paradigm to extract information from an otherwise noisy signal. In Pyro, we can build differentiable Kalman filters using the [`pyro.contrib.tracking` library](http://docs.pyro.ai/en/dev/contrib.tracking.html#module-pyro.contrib.tracking.extended_kalman_filter)\n",
    "\n",
    "## Dynamic process\n",
    "\n",
    "To start, consider this simple motion model:\n",
    "\n",
    "$$ X_{k+1} = FX_k + \\mathbf{W}_k $$\n",
    "$$ \\mathbf{Z}_k = HX_k + \\mathbf{V}_k $$\n",
    "\n",
    "where $k$ is the state, $X$ is the signal estimate, $Z_k$ is the observed value at timestep $k$, $\\mathbf{W}_k$ and  $\\mathbf{V}_k$ are independent noise processes (ie $\\mathbb{E}[w_k v_j^T] = 0$ for all $j, k$) which we'll approximate as Gaussians. Note that the state transitions are linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kalman Update\n",
    "At each time step, we perform a prediction for the mean and covariance:\n",
    "$$ \\hat{X}_k = F\\hat{X}_{k-1}$$\n",
    "$$\\hat{P}_k = FP_{k-1}F^T + Q$$\n",
    "and a correction for the measurement:\n",
    "$$ K_k = \\hat{P}_k H^T(H\\hat{P}_k H^T + R)^{-1}$$\n",
    "$$ X_k = \\hat{X}_k + K_k(z_k - H\\hat{X}_k)$$\n",
    "$$ P_k = (I-K_k H)\\hat{P}_k$$\n",
    "\n",
    "where $X$ is the position estimate, $P$ is the covariance matrix, $K$ is the Kalman Gain, and $Q$ and $R$ are covariance matrices.\n",
    "\n",
    "For an in-depth derivation, see \\[1\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nonlinear Estimation: Extended Kalman Filter\n",
    "\n",
    "What if our system is non-linear, eg in GPS navigation?  Consider this non-linear system:\n",
    "\n",
    "$$ X_{k+1} = \\mathbf{f}(X_k) + \\mathbf{W}_k $$\n",
    "$$ \\mathbf{Z}_k = \\mathbf{h}(X_k) + \\mathbf{V}_k $$\n",
    "\n",
    "Notice that $\\mathbf{f}$ and $\\mathbf{h}$ are now (smooth) non-linear functions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Extended Kalman Filter (EKF) attacks this problem by using a local linearization of the Kalman filter via a [Taylors Series expansion](https://en.wikipedia.org/wiki/Taylor_series).\n",
    "\n",
    "$$ f(X_k, k) \\approx f(x_k^R, k) + \\mathbf{H}_k(X_k - x_k^R) + \\cdots$$\n",
    "\n",
    "where $\\mathbf{H}_k$ is the Jacobian matrix at time $k$, $x_k^R$ is the previous optimal estimate, and we ignore the higher order terms.  At each time step, we compute a Jacobian conditioned the previous predictions (this computation is handled for us under the hood), and use the result to perform a prediction and update.\n",
    "\n",
    "Omitting the derivations, the modification to the above predictions are now:\n",
    "$$ \\hat{X}_k \\approx \\mathbf{f}(X_{k-1}^R)$$\n",
    "$$ \\hat{P}_k = \\mathbf{H}_\\mathbf{f}(X_{k-1})P_{k-1}\\mathbf{H}_\\mathbf{f}^T(X_{k-1}) + Q$$\n",
    "and the updates are now:\n",
    "$$ X_k \\approx \\hat{X}_k + K_k\\big(z_k - \\mathbf{h}(\\hat{X}_k)\\big)$$\n",
    "$$ K_k = \\hat{P}_k \\mathbf{H}_\\mathbf{h}(\\hat{X}_k) \\Big(\\mathbf{H}_\\mathbf{h}(\\hat{X}_k)\\hat{P}_k \\mathbf{H}_\\mathbf{h}(\\hat{X}_k) + R_k\\Big)^{-1} $$\n",
    "$$ P_k = \\big(I - K_k \\mathbf{H}_\\mathbf{h}(\\hat{X}_k)\\big)\\hat{P}_K$$\n",
    "\n",
    "In Pyro, all we need to do is create an `EKFState` object and use its `predict` and `update` methods. Pyro will do exact inference to compute the innovations and we will use SVI to learn a MAP estimate of the position and measurement covariances.\n",
    "\n",
    "As an example, let's look at an object moving at near-constant velocity in 2-D in a discrete time space over 100 time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import pyro\n",
    "from pyro.distributions import MultivariateNormal\n",
    "from pyro.contrib.autoguide import AutoDelta\n",
    "from pyro.optim import Adam\n",
    "from pyro.infer import SVI, Trace_ELBO, config_enumerate\n",
    "from pyro.contrib.tracking.extended_kalman_filter import EKFState\n",
    "from pyro.contrib.tracking.distributions import EKFDistribution\n",
    "from pyro.contrib.tracking.dynamic_models import NcvContinuous\n",
    "from pyro.contrib.tracking.measurements import PositionMeasurement\n",
    "\n",
    "smoke_test = ('CI' in os.environ)\n",
    "pyro.enable_validation(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discrete time\n",
    "dt = 1 / 100\n",
    "num_frames = 10\n",
    "dim = 4\n",
    "\n",
    "# Continuous model\n",
    "ncv = NcvContinuous(dimension=dim, sa2=2.0)\n",
    "\n",
    "# Truth trajectory\n",
    "xs_truth = torch.zeros(num_frames, dim)\n",
    "# initial direction\n",
    "theta0_truth = 0.0\n",
    "# initial state\n",
    "xs_truth[0, :] = torch.tensor([0.0, 0.0, math.cos(theta0_truth), math.sin(theta0_truth)])\n",
    "for frame_num in range(1, num_frames):\n",
    "    # sample independent process noise\n",
    "    dx = pyro.sample('process_noise_{}'.format(frame_num), ncv.process_noise_dist(dt))\n",
    "    xs_truth[frame_num, :] = ncv(xs_truth[frame_num-1, :], dt=dt) + dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Measurements\n",
    "measurements = []\n",
    "mean = torch.zeros(2)\n",
    "# no correlations\n",
    "cov = 1e-5 * torch.eye(2)\n",
    "# sample independent measurement noise\n",
    "dzs = pyro.sample('dzs', MultivariateNormal(mean, cov).expand((num_frames,)))\n",
    "# compute measurement means\n",
    "zs = xs_truth[:, :2] + dzs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(data):\n",
    "    R = pyro.sample('R', dist.LogNormal(1., 1.)) * torch.eye(4)\n",
    "    Q = pyro.sample('Q', dist.LogNormal(1., 1.)) * torch.eye(2)\n",
    "    # observe the measurements\n",
    "    pyro.sample('track_{}'.format(i), EKFDistribution(xs_truth[0], R, ncv,\n",
    "                                                      Q, time_steps=num_frames),\n",
    "                obs=data)\n",
    "    \n",
    "guide = AutoDelta(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss:  47.574042201042175\n",
      "loss:  45.49557280540466\n",
      "loss:  43.53862643241882\n",
      "loss:  41.70700752735138\n",
      "loss:  40.00416624546051\n",
      "loss:  38.43302273750305\n",
      "loss:  36.99586057662964\n",
      "loss:  35.69414782524109\n",
      "loss:  34.52836811542511\n",
      "loss:  33.49785327911377\n",
      "loss:  32.60059905052185\n",
      "loss:  31.833141565322876\n",
      "loss:  31.190431833267212\n",
      "loss:  30.66579782962799\n",
      "loss:  30.25099265575409\n",
      "loss:  29.936315059661865\n",
      "loss:  29.710856199264526\n",
      "loss:  29.562790632247925\n",
      "loss:  29.479783415794373\n",
      "loss:  29.449408411979675\n",
      "loss:  29.45954966545105\n",
      "loss:  29.498809576034546\n",
      "loss:  29.55682396888733\n",
      "loss:  29.624511241912842\n",
      "loss:  29.694225788116455\n",
      "loss:  29.759836196899414\n",
      "loss:  29.816715240478516\n",
      "loss:  29.86168074607849\n",
      "loss:  29.892847537994385\n",
      "loss:  29.909519910812378\n",
      "loss:  29.9119553565979\n",
      "loss:  29.901209592819214\n",
      "loss:  29.878931760787964\n",
      "loss:  29.84717559814453\n",
      "loss:  29.808237075805664\n",
      "loss:  29.764477729797363\n",
      "loss:  29.718207359313965\n",
      "loss:  29.671549558639526\n",
      "loss:  29.62637233734131\n",
      "loss:  29.584218978881836\n",
      "loss:  29.546273469924927\n",
      "loss:  29.51334047317505\n",
      "loss:  29.485862255096436\n",
      "loss:  29.463948011398315\n",
      "loss:  29.447410583496094\n",
      "loss:  29.435824871063232\n",
      "loss:  29.42859148979187\n",
      "loss:  29.424989223480225\n",
      "loss:  29.424248576164246\n",
      "loss:  29.425580263137817\n"
     ]
    }
   ],
   "source": [
    "optim = pyro.optim.Adam({'lr': 0.2})\n",
    "svi = SVI(model, guide, optim, loss=Trace_ELBO())\n",
    "\n",
    "pyro.set_rng_seed(0)\n",
    "pyro.clear_param_store()\n",
    "\n",
    "for i in range(50 if not smoke_test else 2):\n",
    "    loss = svi.step(zs)\n",
    "    print('loss: ', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([-0.0016,  0.0008,  1.0000,  0.0000], grad_fn=<ThSubBackward>),\n",
       " tensor([ 0.0897,  0.0022, -0.1193,  0.0016], grad_fn=<ThSubBackward>),\n",
       " tensor([ 0.0178,  0.0085, -0.0684,  0.0067], grad_fn=<ThSubBackward>),\n",
       " tensor([ 0.0235,  0.0039,  0.0116, -0.0055], grad_fn=<ThSubBackward>),\n",
       " tensor([ 0.0348, -0.0011,  0.0113, -0.0050], grad_fn=<ThSubBackward>),\n",
       " tensor([0.0515, 0.0055, 0.0171, 0.0075], grad_fn=<ThSubBackward>),\n",
       " tensor([ 0.0572, -0.0029,  0.0048, -0.0096], grad_fn=<ThSubBackward>),\n",
       " tensor([ 0.0690, -0.0048,  0.0123, -0.0013], grad_fn=<ThSubBackward>),\n",
       " tensor([ 0.0800, -0.0019,  0.0110,  0.0032], grad_fn=<ThSubBackward>),\n",
       " tensor([ 0.0828, -0.0083,  0.0021, -0.0071], grad_fn=<ThSubBackward>)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = guide()['R'] * torch.eye(4)\n",
    "Q = guide()['Q'] * torch.eye(2)\n",
    "ekf_dist = EKFDistribution(xs_truth[0], R, ncv, Q, time_steps=num_frames)\n",
    "states, innovations = ekf_dist.get_states(zs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRUTH\n",
    "[x[:2] for x in xs_truth.numpy().tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[-0.0016402173787355423, 0.0008416093769483268],\n",
       " [0.08970636129379272, 0.0021629068069159985],\n",
       " [0.01775578409433365, 0.008512821048498154],\n",
       " [0.023472897708415985, 0.003906172700226307],\n",
       " [0.03478563576936722, -0.0011203686008229852],\n",
       " [0.051492709666490555, 0.005487498827278614],\n",
       " [0.05721009895205498, -0.002855192869901657],\n",
       " [0.06895408779382706, -0.004760378506034613],\n",
       " [0.08001435548067093, -0.0019312351942062378],\n",
       " [0.08280424773693085, -0.008302029222249985]]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STATE MEANS\n",
    "[s.mean[:2].detach().numpy().tolist() for s in states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0.07635901868343353, 0.0], [0.0, 0.07635901868343353]],\n",
       " [[0.0887937992811203, 0.0], [0.0, 0.0887937992811203]],\n",
       " [[0.09159314632415771, 0.0], [0.0, 0.09159314632415771]],\n",
       " [[0.09162957221269608, 0.0], [0.0, 0.09162957221269608]],\n",
       " [[0.09163796901702881, 0.0], [0.0, 0.09163796901702881]],\n",
       " [[0.09163802117109299, 0.0], [0.0, 0.09163802117109299]],\n",
       " [[0.09163804352283478, 0.0], [0.0, 0.09163804352283478]],\n",
       " [[0.09163803607225418, 0.0], [0.0, 0.09163803607225418]],\n",
       " [[0.09163803607225418, 0.0], [0.0, 0.09163803607225418]],\n",
       " [[0.09163803607225418, 0.0], [0.0, 0.09163803607225418]]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STATE COV\n",
    "[s.cov[:2, :2].detach().numpy().tolist() for s in states]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INNOVATION COV\n",
    "[i[0].detach().numpy().tolist() for i in innovations]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[0.46201056241989136, 0.0], [0.0, 0.46201056241989136]],\n",
       " [[1.2050361633300781, 0.0], [0.0, 1.2050361633300781]],\n",
       " [[1.888930082321167, 0.0], [0.0, 1.888930082321167]],\n",
       " [[1.9029815196990967, 0.0], [0.0, 1.9029815196990967]],\n",
       " [[1.9062511920928955, 0.0], [0.0, 1.9062511920928955]],\n",
       " [[1.9062671661376953, 0.0], [0.0, 1.9062671661376953]],\n",
       " [[1.9062767028808594, 0.0], [0.0, 1.9062767028808594]],\n",
       " [[1.9062762260437012, 0.0], [0.0, 1.9062762260437012]],\n",
       " [[1.9062762260437012, 0.0], [0.0, 1.9062762260437012]],\n",
       " [[1.9062762260437012, 0.0], [0.0, 1.9062762260437012]]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# INNOVATION COV\n",
    "[i[1].detach().numpy().tolist() for i in innovations]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/html"
   },
   "source": [
    "<center><figure>\n",
    "    <table>\n",
    "        <tr>\n",
    "            <td> \n",
    "                <img src=\"_static/img/ekf_track.png\" style=\"width: 450px;\">\n",
    "            </td>\n",
    "        </tr>\n",
    "    </table> <center>\n",
    "    <figcaption> \n",
    "        <font size=\"+1\"><b>Figure 1:</b>True track and EKF prediction with error. </font> \n",
    "    </figcaption> </center>\n",
    "</figure></center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
